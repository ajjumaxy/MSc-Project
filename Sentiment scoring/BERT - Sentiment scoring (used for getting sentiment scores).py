# -*- coding: utf-8 -*-
"""BERT - Sentiment scoring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nsms1VNooJMlovgZjYpmyhZhogsbxNcM

# **BERT - Fine-tuning**

<hr>

**Author: Daniel Stancl**

**Description:** The notebook used for scoring employee reviews with fine-tuned BERT models from BERT - Fine-tuning.ipynb

1 GPU is used

# **==SPECIFY THE MODEL'S CHECKPOINT TO LOAD ITS STATE==**
"""

CHECKPOINT_PATH = '/content/drive/My Drive/MSc Project/checkpoint.pt'

"""# **Settings**"""

!pip install pytorch-lightning==0.8.5
!pip install tensorboard==2.3.0
!pip install transformers==2.10.0

# Commented out IPython magic to ensure Python compatibility.
# import libraries and settings
from os import listdir
from os.path import isfile, join
import numpy as np
from numpy.random import random, seed
import pandas as pd

import torch
from torch import nn, optim
import torch.nn.functional as F
from torch.utils.data import Dataset, TensorDataset, DataLoader
import pytorch_lightning as pl
from pytorch_lightning import LightningModule, Trainer

import transformers
from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup

from google.colab import drive
drive.mount('/content/drive/', force_remount=True)
# %cd 'drive/My Drive'

"""# **==Functions==**"""

def softmax(X):
  """
  args:
    X: numpy.array of size (N, 1) -> output: numpy.array of size (N,1)
  """
  return np.array(
      [np.exp(x) / np.exp(X).sum() for x in X]
  )

def probabilities_to_sentimentScore(x):
  """
  args:
    x: numpy.array of size (N, 1) -> output: float
  """
  return x[2] - x[0]

"""# **BERT - Import module + Load the state**"""

# Commented out IPython magic to ensure Python compatibility.
# choose the dir
# %cd 'MSc Project/'

from SentimentClassifier import BERT_SentimentClassifier

# obsolete

BERT_parameters = {
    'PRE_TRAINED_MODEL_NAME': 'bert-base-cased',
    'BATCH_SIZE': 16,
    'NUM_WORKERS': 40,
    'DROPOUT_PROB': 0.1,
    'N_CLASSES': 3,
    'N_EPOCHS': 4,
    'LEARNING_RATE': 4e-5,
    'DATA_PATH': '/content/drive/My Drive/MSc Project/Data/',
}

BERT_clf = BERT_SentimentClassifier(**BERT_parameters)
BERT_clf.load_state_dict(torch.load(CHECKPOINT_PATH))
BERT_clf.freeze()

"""# **Load the data**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd 'Data/To predict'

attention_mask = torch.load('ATTENTION_MASK.pt')
input_ids = torch.load('INPUT_IDS.pt')

"""# **Prepare batches**"""

batch_size = 2*BERT_parameters['BATCH_SIZE']

"""# **Score the data**"""

logits = np.concatenate(
    [BERT_clf(input, attention).numpy() for input, attention in zip(input_ids.split(split_size=batch_size), attention_mask.split(split_size=batch_size))]
)

probabilities = np.array(
    [softmax(logit) for logit in logits]
)

sentiment_score = np.array(
    [probabilities_to_sentimentScore(prob) for prob in probabilities]
)

np.save(sentiment_score, 'PREDICTIONS.npy')

